---
layout: single
title:  "[Object Detection -4]SPPNet"

categories:
  - Computer Vision
tags:
  - 
---

4.1 SPPNet 등장 배경
---

SPPNet은 CNN 구조가 고정된 입력 이미지 크기를 입력으로 취하는 데에서 발생한 문제점을 개선하기  
위해서 고안되었다.  
앞서 RCNN에서 Region Proposal된 이미지를 crop/warp을 한 이유 역시 고정된 입력 이미지 크기를 취하기 위해서 였다.  
하지만 crop/warp를 적용하면 문제점이 발생한다.

![1](/assets/images/cv-4/1.JPG)

다음과 같이 이미지의 정보가 손실이 발생한다. 

SPPNet은 FC layer 이전에 Spatial Pyramid layer를 추가해 임의의 사이즈로 입력을 취할 수 있게 한다.

![2](/assets/images/cv-4/2.JPG)

다음 그림처럼 spatial pyramid pooling layer를 추가해 crop/warp 단계를 제거했다.

4.2 SPPNet
---

SPPNet은 RCNN과 다르게 원본 이미지를 imagenet 모델에 넣어 feature map을 먼저 생성한 뒤 원본 이미지의  
selective search를 통해 얻은 bbox를 feature map에 mapping을 한 후 SPP layer를 통해 FC layer로 vector를 만든다.

![3](/assets/images/cv-4/3.JPG)

4.3 SPP layer
---

SPP layer는 어떻게 작동하는지 알아보자.

![4](/assets/images/cv-4/4.JPG)

feature map에서 얻은 bbox에서 spatial bins의 개수를 선정한다.  
예를들면, 위 그림처럼 bbox를 [4x4, 2x2, 1x1] 이런식으로 pooling을 하면 어떤 사이즈의 bbox던지 고정된 vector의 size를  
갖출수 있다. 즉, feature map 크기와 관계없이 bin과 feature map filter 수로 출력 차원을 계산하므로 고정된 차원 벡터를  
갖게된다. 이를 통해 다양한 입력이미지 크기를 입력 받아 다양한 feature map size가 생성되고 SPP layer를 거쳐 고정된 크기의  
벡터가 생성된다.

![5](/assets/images/cv-4/5.JPG)

4.4 SPPNet 작동 방식
---

정리를 해보면,

1. Selective Search를 사용하여 약 2000개의 region proposals를 생생한다.
2. 원본 이미지를 ImageNet에 통과시켜 feature map을 얻는다.
3. 각 region proposal로 경계가 제한된 feature map을 SPP layer에 전달한다.
4. SPP layer를 적용하여 얻은 고정된 벡터 크기(representation)를 FC layer에 전달한다.
5. SVM으로 클래스를 분류한다.
6. Bounding box regression으로 bounding box 크기를 조정하고 non-maximum suppression을 사용하여 최종 bounding box를 선별합니다.


### 출처 : 인프런 "딥러닝 컴퓨터 비전"  
