---
layout: single
title:  "[딥러닝 1-4]합성곱 신경망(CNN)"

categories:
  - 딥러닝 이론
tags:
  - CNN
  - 합성곱
  - Pooling
  - 스프라이드
  - LeNet
  - AlexNet
---

**이 글은 밑바닥부터 시작하는 딥러닝 1 책을 참고로 작성**

[밑바닥부터 시작하는 딥러닝 1](https://github.com/WegraLee/deep-learning-from-scratch)

[출처 블로그](https://youngq.tistory.com/40)

4.1 CNN 이란?
---

![1](/assets/images/CNN/1.PNG)

Convolutuinal Neural Network의 약자로 일반 Deep Neural Network에서 이미지나 영상과 같은  
데이터를 처리할 때 발생하는 문제점들을 보완한 방법

4.2 CNN 알고리즘 구조
---

![2](/assets/images/CNN/2.PNG)

**CNN은 Convolution Layer, Pooling Layer, Fully-connected Layer 단계**로 이루어진 구조이다.  
Convolution Layer, Pooling Layer에서 특징맵이 만들어지는데, 두 Layer 사이에 정규화 계층을 포함하기도  
한다.

4.3 합성곱 계층(Convolution Layer)
---

CNN에서는 패딩, 스프라이드 등 CNN 고유의 용어가 등장한다. 그리고 각 계층 사이에 3차원 데이터같이  
입체적인 데이터가 흐른다는 점에서 완전연결 신경망과 다르다.

### 4.3.1 완전연결 계층의 문제점

완전연결계층에서는 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할 수 있다.  
하지만, 완전연결계층은 데이터의 형상이 무시된다. 예를 들면, 이미지는 3차원데이터(가로, 세로, 색상)이지만  
완전연결계층에 입력할 때는 1차원 데이터로 바꿔줘야 한다. 그렇기 때문에 형상에 담긴 정보를 살릴 수 없다.

예를들면, 다음과 같은 사진을 학습한다고 가정하자.

![3](/assets/images/CNN/3.PNG)

이러한 사진을 완전연결계층에 입력하기 위해 1차원 데이터로 바꿔주면,

![4](/assets/images/CNN/4.PNG)

다음과 같이 기존의 이미지의 형상을 반영해 학습할 수 없다. 즉, 이미지상의 연간 관계가 제거된다.

따라서 CNN에서는 합성곱 계층의 입출력 데이터를 특징맵이라 하고, 입력 데이터를 입력 특징 맵, 출력  
데이터를 출력 특징 맵이라고 한다.

### 4.3.2 합성곱 연산

합성곱 연산은 이미지 처리에서 말하는 필터 연산이다. 입력 데이터에 필터를 적용한다.

필터의 윈도우를 일정 간격으로 이동해 가면서 입력 데이터에 적용한다. 윈도우는 회색 부분을 말한다.  
입력과 필터에 대응하는 원소끼리 곱한 후에 그 총합을 구한다.

![5](/assets/images/CNN/5.PNG)

CNN에서 SMS 필터의 매개변수가 가중치에 해당하고 편향 또하나 존재할 수 있다. 필터를 적용한 후에  
편향을 더한다. 편향은 항상 하나만 존재한다.

### 4.3.3 패딩

합성곱 연산을 수행하기 전에 입력 데이터 주변을 0과 같은 특정 값으로 채우기도 하는 것을 패딩이라고 한다.  
패딩은 주로 출력 크기를 조정할 목적으로 사용한다.

![6](/assets/images/CNN/6.PNG)

이 그림을 보면 패딩이 추가되어서 입력 데이터가 (6,6)이 된다. 이 입력에 (3,3) 필터를 걸면  
(4,4) 출력 데이터가 만들어 진다.

### 4.3.4 스프라이드

필터를 적용하는 위치의 간격을 스프라이드라고 한다. 위의 예는 모두 스프라이드가 1이었지만,  
스프라이드를 2로 하면 윈도우가 두 칸씩 이동한다.

![7](/assets/images/CNN/7.PNG)

스프라이드를 키우면 출력 크기는 작아지고 패딩을 크게 하면 출력 크기가 커진다. 이를 수식화하면,  
다음과 같다.

입력 크기를 (H,W), 필터 크기를 (FH,FW), 출력 크기를 (OH,OW), 패딩을 P, 스프라이드를 S라고 하면  
출력 크기는

OH = (H+2P-FH)/S + 1

OW = (W+2P-FW)/S + 1

딥러닝 프레임워크 중에는 값이 딱 나눠떨어지지 않을 때는 가장 가까운 정수로 반올림한다.

### 4.3.5 3차원 데이터의 합성곱 연산

입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고 그 결과를 더해서 하나의 출력을 얻는다.

![8](/assets/images/CNN/8.PNG)

이 때 주의할 점은 입력 데이터의 채널수와 필터의 채널수가 같아야 한다는 것이다. 이 예에서는  
3개로 같다.

### 4.3.6 배치 처리

신경망 처리에서는 입력 데이터를 한 덩어리로 묶어 배치로 처리했다.

합성곱 연산에서는 4차원 데이터로 저장한다.(데이터 수, 채널 수, 높이, 너비)  
4차원 데아터가 하나 흐를 때마다 데이터 n개에 대한 합성곱 연산이 이뤄진다. 즉, N회분의 처리를  
한번에 수행한다.

4.5 풀링 계층
---

풀링은 세로, 가로 방향의 공간을 줄이는 연산이다. 최대 풀링(Max pooling)은 대상 영역 중에서 최댓값을 구하는 것이다.  
설정한 스프라이드의 크기 대로 윈도우를 설정하고 그 간격으로 이동한다.

![9](/assets/images/CNN/9.PNG)

이 그림을 보면 2x2 최대 풀링을 스프라이드 2로 처리하는 것이다. 2x2 크기의 영역에서 가장 큰 원소  
하나를 꺼내고 스프라이드 2로 설정했으므로 2x2 윈도우가 2칸 간격으로 이동한다.

4.6 Flatten 계층
---

합성곱과 풀링을 반복해주면 이미지의 숫자는 많아지면서 크기는 점점 줄어들게 된다.  
이것은 최종적으로 도출된 nxn 이미지는 이미지라는 의미보다는 특정 이미지에서 얻어온 하나의 특이점 데이터가 된다는 것이다.  
그 말은 2차원이 아닌 1차원의 ROW 데이터로 취급해도 무관한 상태가 된다.  
따라서 하나의 이미지로부터 다양한 특이점들을 뽑아내고 이것을 1차원의 데이터로 변형하는 것이 Flatten이다.

4.7 대표적인 CNN
---

### 4.7.1 LeNet

손글씨 숫자를 인식하는 네트워크이다. 합성곱 계층과 풀링 계층을 반복하고 마지막으로 완전연결 계층을 거치면서 결과를 출력한다.

LeNet과 현재의 CNN과의 차이점

- LeNet는 시그모이드 함수를 사용하고 현재는 ReLU를 사용한다.
- LeNet는 서브샘플링을 하여 중간데이터 크기가 작아지지만 현재는 최대 풀링이 주류다.

### 4.7.2 AlexNet

합성곱 계층과 풀링 계층을 거듭하며 마지막으로 완전연결 계층을 사용하지만, 다음과 같은  
변화가 있다.

- 활성화 함수로 ReLU를 사용한다.
- LRN이라는 국소적 정규화를 실시하는 계층을 이용한다.
- 드롭아웃을 사용한다.

4.8 정리
---

- CNN은 Convolutuinal Neural Network의 약자로 일반 Deep Neural Network에서 이미지나 영상과 같은  
데이터를 처리할 때 발생하는 문제점들을 보완한 방법
- CNN은 합성곱 계층, 풀링 계층, Flatten 계층이 추가된 DNN이라고 보면 된다.
- 대표적인 CNN은 LeNet, AlexNet 등이 있다.
